import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import pandas as pd
from src.clustering.preprocess import preprocess_series
from src.clustering.hierarchical import run_linkage_and_dendrogram
from src.similarity.ai_models import load_sentence_model
from src.similarity.vector_models import compute_embeddings

# Rutas base
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
DATA_DIR = os.path.join(BASE_DIR, "data")
INPUT_FILE = os.path.join(DATA_DIR, "download/unified.csv")
CLUSTERING_DIR = os.path.join(DATA_DIR, "clustering")

# Crear directorio de clustering si no existe
os.makedirs(CLUSTERING_DIR, exist_ok=True)

print("üîç Requerimiento 3 - An√°lisis de clustering jer√°rquico")
print(f"üìÇ Leyendo archivo: {INPUT_FILE}")

# ---------- Validar archivo ----------
if not os.path.exists(INPUT_FILE):
    raise FileNotFoundError(f"No se encontr√≥ el archivo: {INPUT_FILE}\n"
                          f"Aseg√∫rate de ejecutar primero run_downloader.py")

# ---------- Cargar datos ----------
df = pd.read_csv(INPUT_FILE)
print(f"üìÑ Se cargaron {len(df)} art√≠culos")

# Seleccionar art√≠culos: pedir al usuario o usar todos
subset = df  # o filtrar por √≠ndice / selecci√≥n

# Validar que haya abstracts
if "abstract" not in subset.columns:
    raise ValueError("El archivo no contiene la columna 'abstract'")

# Filtrar abstracts vac√≠os
subset = subset[subset['abstract'].notna()]
subset = subset[subset['abstract'].astype(str).str.strip() != '']
print(f"üìÑ Art√≠culos con abstract v√°lido: {len(subset)}")

if len(subset) == 0:
    raise ValueError("No hay art√≠culos con abstracts v√°lidos para procesar")

# ---------- Preprocesamiento ----------
print("\nüîß Preprocesando textos...")
texts = preprocess_series(subset['abstract'], do_lemmatize=False)
print(f"‚úÖ Textos preprocesados: {len(texts)}")

# ---------- Embeddings sem√°nticos ----------
print("\nü§ñ Cargando modelo de embeddings...")
model = load_sentence_model()

print("üßÆ Generando embeddings...")
embs = compute_embeddings(model, texts).cpu().numpy()
print(f"‚úÖ Embeddings generados: {embs.shape}")

# ---------- Preparar etiquetas ----------
labels = subset['title'].fillna('Sin t√≠tulo').apply(lambda s: s[:80]).tolist()

# ---------- Clustering con diferentes m√©todos ----------
print("\nüå≥ Generando dendrogramas con diferentes m√©todos de linkage...")
methods = ['single', 'complete', 'average']
results = {}

for m in methods:
    print(f"\n  üìä Procesando m√©todo: {m}")
    out_file = os.path.join(CLUSTERING_DIR, f"dendrogram_{m}.png")
    
    try:
        Z, coph = run_linkage_and_dendrogram(
            embs, 
            labels, 
            method=m, 
            metric='cosine', 
            out_path=out_file
        )
        results[m] = coph
        print(f"     ‚úÖ Dendrograma guardado: {out_file}")
        print(f"     üìà Coeficiente cofon√©tico: {coph:.4f}")
    except Exception as e:
        print(f"     ‚ö†Ô∏è Error en m√©todo {m}: {e}")
        results[m] = 0.0

# ---------- Resultados ----------
print("\n" + "="*60)
print("üìä RESULTADOS DEL AN√ÅLISIS DE CLUSTERING")
print("="*60)

print("\nüî¢ Coeficientes cofon√©ticos por m√©todo:")
for method, coph in sorted(results.items(), key=lambda x: x[1], reverse=True):
    print(f"   ‚Ä¢ {method:10s}: {coph:.4f}")

if results:
    best = max(results, key=results.get)
    best_coph = results[best]
    print(f"\nüèÜ Mejor m√©todo: {best.upper()} (coeficiente: {best_coph:.4f})")
    print(f"\nüí° Interpretaci√≥n:")
    if best_coph > 0.8:
        print("   ‚úÖ Excelente correlaci√≥n - El clustering representa muy bien las distancias")
    elif best_coph > 0.7:
        print("   ‚úÖ Buena correlaci√≥n - El clustering es confiable")
    elif best_coph > 0.6:
        print("   ‚ö†Ô∏è  Correlaci√≥n moderada - El clustering es aceptable")
    else:
        print("   ‚ö†Ô∏è  Correlaci√≥n baja - Considera revisar los datos o m√©todo")
else:
    print("\n‚ö†Ô∏è  No se pudo calcular ning√∫n m√©todo de clustering")

print(f"\nüìÅ Dendrogramas guardados en: {CLUSTERING_DIR}")
print("\n‚úÖ Proceso completado exitosamente!")