import os
import sys

# Agregar el directorio ra√≠z del proyecto al sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import asyncio
from src.download.downloader import run_all
from src.download.merger import merge_and_deduplicate

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Descarga y unifica art√≠culos cient√≠ficos (Requerimiento 1).")
    parser.add_argument("--query", "-q", default="generative artificial intelligence", help="Cadena de b√∫squeda")
    parser.add_argument("--max", "-m", type=int, default=30, help="N√∫mero m√°ximo de art√≠culos por base de datos")
    parser.add_argument("--headless", action="store_true", help="Ejecutar sin interfaz gr√°fica (modo headless)")
    parser.add_argument("--delay", type=float, default=1.0, help="Retraso entre acciones (segundos)")
    args = parser.parse_args()

    print(f"\nüîç Iniciando scraping con query: '{args.query}'")
    asyncio.run(run_all(
        query=args.query,
        max_results=args.max,
        headless=args.headless,
        delay_between_requests=args.delay
    ))

    print("\nüìÇ Unificando y eliminando duplicados...")
    merge_and_deduplicate()
    print("\n‚úÖ Proceso terminado. Revisa la carpeta 'data/' para ver los CSV generados.")
